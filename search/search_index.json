{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"Model/encoders/","title":"Encoders","text":""},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder","title":"ShoeboxEncoder","text":"<pre><code>ShoeboxEncoder(data_dim: int, input_shape: tuple[int, ...] = (3, 21, 21), in_channels: int = 1, encoder_out: int = 64, conv1_out_channels: int = 16, conv1_kernel_size: tuple[int, int, int] = (1, 3, 3), conv1_padding: tuple[int, int, int] = (0, 1, 1), norm1_num_groups: int = 4, pool_kernel_size: tuple[int, int, int] = (1, 2, 2), pool_stride: tuple[int, ...] = (1, 2, 2), conv2_out_channels: int = 32, conv2_kernel_size: tuple[int, int, int] = (3, 3, 3), conv2_padding: tuple[int, int, int] = (0, 0, 0), norm2_num_groups: int = 4)\n</code></pre> <p>               Bases: <code>nn.Module</code></p> <p>3D CNN encoder producing a fixed-length embedding from a shoebox volume.</p> <p>This module applies two Conv3d + GroupNorm + ReLU blocks with an intermediate MaxPool3d, then flattens and projects to <code>encoder_out</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tuple[int, ...]</code> <p>Shoebox spatial dimensions as <code>(D, H, W)</code>.</p> <code>(3, 21, 21)</code> <code>in_channels</code> <code>int</code> <p>Number of input channels (<code>C</code>).</p> <code>1</code> <code>encoder_out</code> <code>int</code> <p>Output embedding dimension.</p> <code>64</code> <code>conv1_out_channels</code> <code>int</code> <p>Output channels of the first 3D convolution.</p> <code>16</code> <code>conv1_kernel_size</code> <code>tuple[int, int, int]</code> <p>Kernel size for the first 3D convolution.</p> <code>(1, 3, 3)</code> <code>conv1_padding</code> <code>tuple[int, int, int]</code> <p>Padding for the first 3D convolution.</p> <code>(0, 1, 1)</code> <code>norm1_num_groups</code> <code>int</code> <p>Number of groups for the first GroupNorm.</p> <code>4</code> <code>pool_kernel_size</code> <code>tuple[int, int, int]</code> <p>MaxPool3d kernel size.</p> <code>(1, 2, 2)</code> <code>pool_stride</code> <code>tuple[int, ...]</code> <p>MaxPool3d stride.</p> <code>(1, 2, 2)</code> <code>conv2_out_channels</code> <code>int</code> <p>Output channels of the second 3D convolution.</p> <code>32</code> <code>conv2_kernel_size</code> <code>tuple[int, int, int]</code> <p>Kernel size for the second 3D convolution.</p> <code>(3, 3, 3)</code> <code>conv2_padding</code> <code>tuple[int, int, int]</code> <p>Padding for the second 3D convolution.</p> <code>(0, 0, 0)</code> <code>norm2_num_groups</code> <code>int</code> <p>Number of groups for the second GroupNorm.</p> <code>4</code>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder-attributes","title":"Attributes","text":""},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.conv1","title":"conv1  <code>instance-attribute</code>","text":"<pre><code>conv1: nn.Conv3d = operations[data_dim]['conv'](in_channels=in_channels, out_channels=conv1_out_channels, kernel_size=conv1_kernel_size, padding=conv1_padding)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.conv1_kernel_size","title":"conv1_kernel_size  <code>instance-attribute</code>","text":"<pre><code>conv1_kernel_size: tuple[int, int, int]\n</code></pre> <p>Kernel size for the first convolution as <code>(kD, kH, kW)</code>.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.conv1_out_channels","title":"conv1_out_channels  <code>instance-attribute</code>","text":"<pre><code>conv1_out_channels: int\n</code></pre> <p>Number of output channels for the first convolution.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.conv1_padding","title":"conv1_padding  <code>instance-attribute</code>","text":"<pre><code>conv1_padding: tuple[int, int, int]\n</code></pre> <p>Padding for the first convolution as <code>(pD, pH, pW)</code>.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.conv2","title":"conv2  <code>instance-attribute</code>","text":"<pre><code>conv2: nn.Conv3d = operations[data_dim]['conv'](in_channels=conv1_out_channels, out_channels=conv2_out_channels, kernel_size=conv2_kernel_size, padding=conv2_padding)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.data_dim","title":"data_dim  <code>instance-attribute</code>","text":"<pre><code>data_dim: str\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.encoder_out","title":"encoder_out  <code>instance-attribute</code>","text":"<pre><code>encoder_out: int = encoder_out\n</code></pre> <p>Dimensionality of the output embedding.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.fc","title":"fc  <code>instance-attribute</code>","text":"<pre><code>fc = nn.Linear(in_features=self.flattened_size, out_features=encoder_out)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.flattened_size","title":"flattened_size  <code>instance-attribute</code>","text":"<pre><code>flattened_size: int = self._infer_flattened_size(input_shape=input_shape, in_channels=in_channels)\n</code></pre> <p>Internal: flattened feature size inferred from a dummy pass.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.in_channels","title":"in_channels  <code>instance-attribute</code>","text":"<pre><code>in_channels: int\n</code></pre> <p>Number of input channels (C) in the 3D volume.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.input_shape","title":"input_shape  <code>instance-attribute</code>","text":"<pre><code>input_shape: tuple[int, int, int]\n</code></pre> <p>Shoebox shape as <code>(D, H, W)</code>.</p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.norm1","title":"norm1  <code>instance-attribute</code>","text":"<pre><code>norm1: nn.GroupNorm = nn.GroupNorm(num_groups=norm1_num_groups, num_channels=conv1_out_channels)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.norm2","title":"norm2  <code>instance-attribute</code>","text":"<pre><code>norm2: nn.GroupNorm = nn.GroupNorm(num_groups=norm2_num_groups, num_channels=conv2_out_channels)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.pool","title":"pool  <code>instance-attribute</code>","text":"<pre><code>pool: nn.MaxPool3d = operations[data_dim]['max_pool'](kernel_size=pool_kernel_size, stride=pool_stride, ceil_mode=True)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder-functions","title":"Functions","text":""},{"location":"Model/encoders/#integrator.model.encoders.encoders.ShoeboxEncoder.forward","title":"forward","text":"<pre><code>forward(x)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder","title":"IntensityEncoder","text":"<pre><code>IntensityEncoder(data_dim: str, in_channels=1, encoder_out=64, conv1_out_channels=16, conv1_kernel_size=(3, 3), conv1_padding=(1, 1), norm1_num_groups=4, pool_kernel_size=(2, 2), pool_stride=(2, 2), conv2_out_channels=32, conv2_kernel_size=(3, 3), conv2_padding=(0, 0), norm2_num_groups=4, conv3_out_channels=64, conv3_kernel_size=(3, 3), conv3_padding=(1, 1), norm3_num_groups=8)\n</code></pre> <p>               Bases: <code>nn.Module</code></p>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder-attributes","title":"Attributes","text":""},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.adaptive_pool","title":"adaptive_pool  <code>instance-attribute</code>","text":"<pre><code>adaptive_pool = operations[data_dim]['adaptive_pool'](1)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.conv1","title":"conv1  <code>instance-attribute</code>","text":"<pre><code>conv1 = operations[data_dim]['conv'](in_channels=in_channels, out_channels=conv1_out_channels, kernel_size=conv1_kernel_size, padding=conv1_padding)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.conv2","title":"conv2  <code>instance-attribute</code>","text":"<pre><code>conv2 = operations[data_dim]['conv'](in_channels=conv1_out_channels, out_channels=conv2_out_channels, kernel_size=conv2_kernel_size, padding=conv2_padding)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.conv3","title":"conv3  <code>instance-attribute</code>","text":"<pre><code>conv3 = operations[data_dim]['conv'](in_channels=conv2_out_channels, out_channels=conv3_out_channels, kernel_size=conv3_kernel_size, padding=conv3_padding)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.fc","title":"fc  <code>instance-attribute</code>","text":"<pre><code>fc = nn.Linear(in_features=conv3_out_channels, out_features=encoder_out)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.norm1","title":"norm1  <code>instance-attribute</code>","text":"<pre><code>norm1 = nn.GroupNorm(num_groups=norm1_num_groups, num_channels=conv1_out_channels)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.norm2","title":"norm2  <code>instance-attribute</code>","text":"<pre><code>norm2 = nn.GroupNorm(num_groups=norm2_num_groups, num_channels=conv2_out_channels)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.norm3","title":"norm3  <code>instance-attribute</code>","text":"<pre><code>norm3 = nn.GroupNorm(num_groups=norm3_num_groups, num_channels=conv3_out_channels)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.pool","title":"pool  <code>instance-attribute</code>","text":"<pre><code>pool = operations[data_dim]['max_pool'](kernel_size=pool_kernel_size, stride=pool_stride, ceil_mode=True)\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder-functions","title":"Functions","text":""},{"location":"Model/encoders/#integrator.model.encoders.encoders.IntensityEncoder.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; Tensor\n</code></pre>"},{"location":"Model/encoders/#integrator.model.encoders.metadata_encoder.MLPMetadataEncoder","title":"MLPMetadataEncoder","text":"<pre><code>MLPMetadataEncoder(encoder_in: int, encoder_out: int, depth: int = 10, dropout: bool | float = 0.0)\n</code></pre> <p>               Bases: <code>nn.Module</code></p> <p>Encoder to be used with experimental metadata associated with each shoebox, such as predicted centroid coordinates, Miller indices, average shoebox intensity, etc. The architecture is based off a Residual Network.</p>"},{"location":"Model/encoders/#integrator.model.encoders.metadata_encoder.MLPMetadataEncoder-attributes","title":"Attributes","text":""},{"location":"Model/encoders/#integrator.model.encoders.metadata_encoder.MLPMetadataEncoder.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Sequential = nn.Sequential(*layers)\n</code></pre> <p>A <code>torch.nn.Sequential</code> container containing the sequence of layers applied to the input shoebox.</p>"},{"location":"Model/encoders/#integrator.model.encoders.metadata_encoder.MLPMetadataEncoder-functions","title":"Functions","text":""},{"location":"Model/encoders/#integrator.model.encoders.metadata_encoder.MLPMetadataEncoder.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; Tensor\n</code></pre>"},{"location":"Model/integrator/","title":"Integrator","text":""},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator","title":"Integrator","text":"<pre><code>Integrator(qbg: BaseDistribution, qp: BaseDistribution, qi: BaseDistribution, loss: BaseLoss, encoder_out: int, encoder1: ShoeboxEncoder | IntensityEncoder, encoder2: ShoeboxEncoder | IntensityEncoder, encoder3: MLPMetadataEncoder | None = None, data_dim: str = '3d', d: int = 3, h: int = 21, w: int = 21, lr: float = 0.001, weight_decay: float = 0.0, mc_samples: int = 100, max_iterations: int = 4, renyi_scale: float = 0.0, predict_keys: list[str] | str = 'default')\n</code></pre> <p>               Bases: <code>LightningModule</code></p> <p>Integrator class to infer intenities from raw X-ray diffraction images and experimental metadata.</p> <p>Methods:</p> Name Description <code>forward</code> <p>Forward model architecture:</p> <code>on_train_epoch_end</code> <p>Aggregate and log training metrics at the end of each epoch.</p> <code>on_validation_epoch_end</code> <p>Aggregate and log validation metrics at the end of each epoch.</p> <code>validation_step</code> <p>Args:</p> <code>predict_step</code> <p>Run inference on a batch during prediction.</p> <p>Attributes:</p> Name Type Description <code>avg_loss</code> <code>list</code> <p>List containing the average train loss per train epoch</p> <code>avg_kl</code> <code>list</code> <p>List containing the average Kullback-Leibler divergence of the train set</p> <code>avg_nll</code> <code>list</code> <p>List containing the average validation negative log-likelihood train epoch</p> <code>qbg</code> <code>BaseDistribution</code> <p>Surrogate posterior shoebox Background</p> <code>qp</code> <code>BaseDistribution</code> <p>Surrogate posterior of spot Profile</p> <code>qi</code> <code>BaseDistribution</code> <p>Surrogate posterior of the spot Intensity</p> <code>d</code> <code>int</code> <p>Depth of input shoebox.</p> <code>h</code> <code>int</code> <p>Height on input shoebox.</p> <code>w</code> <code>int</code> <p>Width of input shoebox.</p> <code>loss</code> <code>BaseLoss</code> <p>Loss function to optimize.</p> <code>data_dim</code> <code>str</code> <p>Dimensionality of diffraction data (2d or 3d)</p> <code>encoder_out</code> <code>int</code> <p>Dimension of the encoder codomain</p> <code>encoder1</code> <code>ShoeboxEncoder | IntensityEncoder</code> <p>Encoder to get profile distribution</p> <code>encoder2</code> <code>ShoeboxEncoder | IntensityEncoder</code> <p>Encoder to get intensity &amp; background distributions</p> <code>encoder3</code> <code>MLPMetadataEncoder | None</code> <p>Optional Encoder for experimental metadata</p> <code>val_loss</code> <code>list</code> <p>List containing the average validation loss per validation epoch</p> <code>val_kl</code> <code>list</code> <p>List containing the average Kullback-Leibler divergence per validation epoch</p> <code>val_nll</code> <code>list</code> <p>List containing the average validation negative log-likelihood validation epoch</p> <code>lr</code> <code>float</code> <p>Learning rate for <code>torch.optim.Adam</code></p> <code>weight_decay</code> <code>float</code> <p>Weight decay value for Adam optimizer.</p> <code>mc_samples</code> <code>int</code> <p>Number of samples to use for Monte Carlo approximations</p> <code>predict_keys</code> <code>str | list[str]</code> <p>List of keys to store during the <code>predict_step</code>.</p> <code>schema</code> <code>list[tuple]</code> <p>A <code>polars.DataFrame</code> schema to define logged metrics</p> <code>train_df</code> <code>pl.DataFrame</code> <p><code>DataFrame</code> with train and validation metrics</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator-attributes","title":"Attributes","text":""},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.avg_loss","title":"avg_loss  <code>instance-attribute</code>","text":"<pre><code>avg_loss: list\n</code></pre> <p>List containing the average train loss per train epoch</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.avg_kl","title":"avg_kl  <code>instance-attribute</code>","text":"<pre><code>avg_kl: list\n</code></pre> <p>List containing the average Kullback-Leibler divergence of the train set</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.avg_nll","title":"avg_nll  <code>instance-attribute</code>","text":"<pre><code>avg_nll: list\n</code></pre> <p>List containing the average validation negative log-likelihood train epoch</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.qbg","title":"qbg  <code>instance-attribute</code>","text":"<pre><code>qbg: BaseDistribution = qbg\n</code></pre> <p>Surrogate posterior shoebox Background</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.qp","title":"qp  <code>instance-attribute</code>","text":"<pre><code>qp: BaseDistribution = qp\n</code></pre> <p>Surrogate posterior of spot Profile</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.qi","title":"qi  <code>instance-attribute</code>","text":"<pre><code>qi: BaseDistribution = qi\n</code></pre> <p>Surrogate posterior of the spot Intensity</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.d","title":"d  <code>instance-attribute</code>","text":"<pre><code>d: int = d\n</code></pre> <p>Depth of input shoebox.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.h","title":"h  <code>instance-attribute</code>","text":"<pre><code>h: int = h\n</code></pre> <p>Height on input shoebox.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.w","title":"w  <code>instance-attribute</code>","text":"<pre><code>w: int = w\n</code></pre> <p>Width of input shoebox.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss: BaseLoss = loss\n</code></pre> <p>Loss function to optimize.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.data_dim","title":"data_dim  <code>instance-attribute</code>","text":"<pre><code>data_dim: str = data_dim\n</code></pre> <p>Dimensionality of diffraction data (2d or 3d)</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.encoder_out","title":"encoder_out  <code>instance-attribute</code>","text":"<pre><code>encoder_out: int = encoder_out\n</code></pre> <p>Dimension of the encoder codomain</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.encoder1","title":"encoder1  <code>instance-attribute</code>","text":"<pre><code>encoder1: ShoeboxEncoder | IntensityEncoder = encoder1\n</code></pre> <p>Encoder to get profile distribution</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.encoder2","title":"encoder2  <code>instance-attribute</code>","text":"<pre><code>encoder2: ShoeboxEncoder | IntensityEncoder = encoder2\n</code></pre> <p>Encoder to get intensity &amp; background distributions</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.encoder3","title":"encoder3  <code>instance-attribute</code>","text":"<pre><code>encoder3: MLPMetadataEncoder | None = encoder3\n</code></pre> <p>Optional Encoder for experimental metadata</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.val_loss","title":"val_loss  <code>instance-attribute</code>","text":"<pre><code>val_loss: list = []\n</code></pre> <p>List containing the average validation loss per validation epoch</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.val_kl","title":"val_kl  <code>instance-attribute</code>","text":"<pre><code>val_kl: list = []\n</code></pre> <p>List containing the average Kullback-Leibler divergence per validation epoch</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.val_nll","title":"val_nll  <code>instance-attribute</code>","text":"<pre><code>val_nll: list = []\n</code></pre> <p>List containing the average validation negative log-likelihood validation epoch</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.lr","title":"lr  <code>instance-attribute</code>","text":"<pre><code>lr: float = lr\n</code></pre> <p>Learning rate for <code>torch.optim.Adam</code></p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.weight_decay","title":"weight_decay  <code>instance-attribute</code>","text":"<pre><code>weight_decay: float = weight_decay\n</code></pre> <p>Weight decay value for Adam optimizer.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.mc_samples","title":"mc_samples  <code>instance-attribute</code>","text":"<pre><code>mc_samples: int = mc_samples\n</code></pre> <p>Number of samples to use for Monte Carlo approximations</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.predict_keys","title":"predict_keys  <code>instance-attribute</code>","text":"<pre><code>predict_keys: str | list[str] = predict_keys\n</code></pre> <p>List of keys to store during the <code>predict_step</code>.</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.schema","title":"schema  <code>instance-attribute</code>","text":"<pre><code>schema: list[tuple] = [('epoch', int), ('avg_loss', float), ('avg_kl', float), ('avg_nll', float)]\n</code></pre> <p>A <code>polars.DataFrame</code> schema to define logged metrics</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.train_df","title":"train_df  <code>instance-attribute</code>","text":"<pre><code>train_df: pl.DataFrame = pl.DataFrame(schema=self.schema)\n</code></pre> <p><code>DataFrame</code> with train and validation metrics</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator-functions","title":"Functions","text":""},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.forward","title":"forward","text":"<pre><code>forward(counts: Tensor, shoebox: Tensor, masks: Tensor, reference: Tensor | None = None) -&gt; dict[str, Any]\n</code></pre> <p>Forward model architecture: <pre><code>flowchart LR\n\n    counts --&gt; encoder1\n    counts --&gt; encoder2\n    metadata --&gt; encoder3\n\n    encoder1 --&gt; qp\n    encoder2 --&gt; torch.concat\n    encoder3 --&gt; torch.concat\n    torch.concat --&gt; qi\n    torch.concat --&gt; qbg\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>Tensor</code> <p>Raw photon count Tensor</p> required <code>shoebox</code> <code>Tensor</code> <p>Standardized photon count Tensor</p> required <code>masks</code> <code>Tensor</code> <p>Dead-pixel mask</p> required <code>reference</code> <code>Tensor | None</code> <p>Optional metadata Tensor</p> <code>None</code> <p>Returns:</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.on_train_epoch_end","title":"on_train_epoch_end","text":"<pre><code>on_train_epoch_end()\n</code></pre> <p>Aggregate and log training metrics at the end of each epoch.</p> <ul> <li>Computes average loss, KL, and NLL over the epoch.</li> <li>Logs values to PyTorch Lightning's logger.</li> <li>Appends a new row to self.train_df.</li> <li>Resets training metric lists for the next epoch.</li> </ul>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.on_validation_epoch_end","title":"on_validation_epoch_end","text":"<pre><code>on_validation_epoch_end()\n</code></pre> <p>Aggregate and log validation metrics at the end of each epoch.</p> <ul> <li>Computes average loss, KL, and NLL over the epoch.</li> <li>Logs values to PyTorch Lightning's logger.</li> <li>Appends a new row to <code>self.val_df</code>.</li> <li>Resets validation metric lists.</li> </ul>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.validation_step","title":"validation_step","text":"<pre><code>validation_step(batch, _batch_idx)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>batch</code> required <p>Returns:</p>"},{"location":"Model/integrator/#integrator.model.integrators.integrator.Integrator.predict_step","title":"predict_step","text":"<pre><code>predict_step(batch: Tensor, _batch_idx)\n</code></pre> <p>Run inference on a batch during prediction.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Tuple of (counts, shoebox, masks, reference).</p> required <p>Returns:</p> Type Description <p>Dictionary with keys specified in self.predict_keys.</p>"},{"location":"Model/distributions/distributions/","title":"Distributions","text":"<p>The distributions modules take as input a transformed shoebox, and then return a parameterized distribution object.  In mathematical terms, the <code>distribution</code> modules are functions \\(f(x) = y\\), where \\(y\\) is a parameterizable distribution, and \\(x\\) is an observed reflection. </p> <p>Positive support distributions to be used as varitional distributions for Intensity and Background latent variables. </p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.base_distribution.BaseDistribution","title":"BaseDistribution","text":"<pre><code>BaseDistribution(in_features: int, out_features: int | tuple[int, ...], constraint: str = 'softplus', eps: float = 1e-12, beta: float = 1.0)\n</code></pre> <p>               Bases: <code>nn.Module</code></p> <p>Base class for parametric distributions. Ensures buffers like eps/beta are device-safe and used consistently.</p> <p>Methods:</p> Name Description <code>forward</code> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.base_distribution.BaseDistribution-functions","title":"Functions","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.base_distribution.BaseDistribution.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; T\n</code></pre> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.folded_normal.FoldedNormalDistribution","title":"FoldedNormalDistribution","text":"<pre><code>FoldedNormalDistribution(in_features: int, out_features: int = 2, eps=0.1, beta=1.0, constraint='softplus')\n</code></pre> <p>               Bases: <code>BaseDistribution[FoldedNormal]</code></p> <p>FoldedNormal distribution with parameters predicted by a linear layer.</p> <p>Methods:</p> Name Description <code>forward</code> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.folded_normal.FoldedNormalDistribution-functions","title":"Functions","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.folded_normal.FoldedNormalDistribution.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; FoldedNormal\n</code></pre> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.gamma.GammaDistribution","title":"GammaDistribution","text":"<pre><code>GammaDistribution(in_features: int, out_features: int = 2, eps: float = 1e-12, beta: float = 1.0)\n</code></pre> <p>               Bases: <code>BaseDistribution[Gamma]</code></p> <p>Parameters:</p> Name Type Description Default <code>in_features</code> <code>int</code> <p>Dimension of input Tensor</p> required <code>out_features</code> <code>int</code> <p>Dimension of the networks parameter Tensor</p> <code>2</code> <p>Methods:</p> Name Description <code>forward</code> <p>Args:</p> <p>Attributes:</p> Name Type Description <code>fc</code> <code>nn.Module</code> <p><code>Linear</code> layer to map input tensors to distribution parameters</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.gamma.GammaDistribution-attributes","title":"Attributes","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.gamma.GammaDistribution.fc","title":"fc  <code>instance-attribute</code>","text":"<pre><code>fc: nn.Module = Linear(in_features=in_features, out_features=out_features)\n</code></pre> <p><code>Linear</code> layer to map input tensors to distribution parameters</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.gamma.GammaDistribution-functions","title":"Functions","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.gamma.GammaDistribution.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; Gamma\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input batch of shoeboxes</p> required <p>Returns:     <code>torch.distributions.Gamma</code></p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.log_normal.LogNormalDistribution","title":"LogNormalDistribution","text":"<pre><code>LogNormalDistribution(in_features: int, out_features: int = 2, constraint: str = 'softplus', eps: float = 1e-12, beta: float = 1.0)\n</code></pre> <p>               Bases: <code>BaseDistribution[LogNormal]</code></p> <p>LogNormal distribution with parameters predicted by a linear layer.</p> <p>Methods:</p> Name Description <code>forward</code> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.log_normal.LogNormalDistribution-functions","title":"Functions","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.log_normal.LogNormalDistribution.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; LogNormal\n</code></pre> <p>To be implemented by subclasses.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.dirichlet.DirichletDistribution","title":"DirichletDistribution","text":"<pre><code>DirichletDistribution(in_features: int = 64, out_features: tuple[int, ...] = (3, 21, 21), **kwargs)\n</code></pre> <p>               Bases: <code>BaseDistribution[Dirichlet]</code></p> <p>Dirichlet distribution with parameters predicted by a linear layer.</p> <p>Parameters:</p> Name Type Description Default <code>in_features</code> <code>int</code> <p>Input feature dimension.</p> <code>64</code> <code>out_features</code> <code>tuple[int, ...]</code> <p><code>(C, H, W)</code> or <code>(H, W)</code> used to calculate dimension of the Diritchlet concentration paramter.</p> <code>(3, 21, 21)</code> <p>Methods:</p> Name Description <code>forward</code> <p>Return a <code>torch.distributions.Dirichlet</code> from an input shoebox</p> <p>Attributes:</p> Name Type Description <code>input_shape</code> <code>tuple[int, ...]</code> <p>Shape of an input shoebox as <code>(C, H, W)</code> or <code>(H, W)</code>.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.dirichlet.DirichletDistribution-attributes","title":"Attributes","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.dirichlet.DirichletDistribution.input_shape","title":"input_shape  <code>instance-attribute</code>","text":"<pre><code>input_shape: tuple[int, ...]\n</code></pre> <p>Shape of an input shoebox as <code>(C, H, W)</code> or <code>(H, W)</code>.</p>"},{"location":"Model/distributions/distributions/#integrator.model.distributions.dirichlet.DirichletDistribution-functions","title":"Functions","text":""},{"location":"Model/distributions/distributions/#integrator.model.distributions.dirichlet.DirichletDistribution.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; Dirichlet\n</code></pre> <p>Return a <code>torch.distributions.Dirichlet</code> from an input shoebox</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input batch of shoeboxes</p> required <p>Returns:</p> Name Type Description <code>qp</code> <code>Dirichlet</code> <p>A <code>torch.distributions.Dirichlet(x)</code></p>"},{"location":"Model/distributions/intensity_and_background_distributions/","title":"Intensity and background distributions","text":"<p>Positive support distributions to be used as varitional distributions for Intensity and Background latent variables. </p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>The integrator is fully specificed with a <code>config.yaml</code> file.  Below are the default configuration settings. </p> 2D3D <pre><code>global_vars:\n  in_features: &amp;in_features 32\n  mc_samples: &amp;mc_samples 100\n  data_dir: &amp;data \"/path/to/data\"\n\nintegrator:\n  name: integrator_2d\n  args:\n    lr: 0.001\n    mc_samples: *mc_samples\n    renyi_scale: 0.0\n    h: 21\n    w: 21\n    weight_decay: 0.0\n\ncomponents:\n  encoders: \n    - encoder1:\n        name: shoebox_encoder_2d\n        args:\n          out_features: *in_features\n          in_channels: 1\n          conv1_out_channels: 16\n          conv2_out_channels: 32\n          conv1_kernel: [3,3]\n          conv1_padding: [1,1]\n\n    - encoder2:\n        name: intensity_encoder_2d\n        args:\n          out_features: *in_features\n          in_channels: 1\n          conv1_out_channels: 16\n          conv2_out_channels: 32\n          conv3_out_channels: 64\n          conv1_kernel: [3,3]\n          conv1_padding: [1,1]\n\n  qp:\n    name: dirichlet\n    args:\n      in_features: *in_features\n      input_shape: [21,21]\n\n  qbg:\n    name: folded_normal\n    args:\n      in_features: *in_features\n      out_features: 2\n\n  qi: \n    name: folded_normal\n    args: \n      in_features: *in_features\n      out_features: 2\n\n  loss:\n    name: loss\n    args:\n      pi_name: half_cauchy\n      pi_params:\n        scale: 0.5\n\n      pbg_name: half_cauchy\n      pbg_params:\n        scale: 0.5\n\n      pprf_name: dirichlet\n      pprf_params:\n        concentration: 1.0\n      pprf_weight: 0.02\n      pbg_weight: 0.5\n      pi_weight: 0.4\n      prior_tensor: \"concentration_2d.pt\"\n      use_robust: false\n\ndata_loader:\n  name: shoebox_data_module_2d\n  args:\n    data_dir: \"/path/to/data\"\n    batch_size: 256\n    val_split: 0.3\n    test_split: 0.0\n    num_workers: 3\n    include_test: false\n    subset_size: null\n    cutoff: null\n    use_metadata: true\n    shoebox_file_names:\n      counts: \"counts_2d_subset.pt\"\n      masks: \"masks_2d_subset.pt\"\n      stats: 'stats_2d.pt'\n      reference: 'reference_2d_subset.pt'\n      standardized_counts: null\n\ntrainer:\n  args:\n    max_epochs: 1000\n    accelerator: auto\n    devices: 1\n    logger: true\n    precision: \"32\"\n    check_val_every_n_epoch: 2\n    log_every_n_steps: 3\n    deterministic: false\n    callbacks:\n      pred_writer:\n        output_dir: null\n        write_interval: epoch\n    enable_checkpointing: true\n\nlogger:\n    d: 3\n    h: 21\n    w: 21\n\noutput:\n  refl_file: \"/path/to/.refl\"\n</code></pre> <pre><code>global_vars:\n  in_features: &amp;in_features 64\n  mc_samples: &amp;mc_samples 100\n  data_dir: &amp;data \"/path/to/data\"\n\nintegrator:\n  name: integrator\n  args:\n    lr: 0.001\n    mc_samples: *mc_samples\n    renyi_scale: 0.0\n    d: 3\n    h: 21\n    w: 21\n    weight_decay: 0.0\n\ncomponents:\n  encoders: \n  - encoder1:\n      name: shoebox_encoder\n      args:\n        out_features: 64\n        in_channels: 1\n        conv1_out_channels: 64\n        conv2_out_channels: 128\n        conv1_kernel: [1,3,3]\n        conv1_padding: [0,1,1]\n\n  - encoder2:\n      name: intensity_encoder\n      args:\n        out_features: 64\n        in_channels: 1\n        conv1_out_channels: 64\n        conv2_out_channels: 128\n        conv3_out_channels: 256\n        conv1_kernel: [3,3,3]\n        conv1_padding: [1,1,1]\n\n  qp:\n    name: dirichlet\n    args: \n      in_features: *in_features\n      input_shape: [3,21,21]\n\n  qbg:\n    name: folded_normal\n    args:\n      in_features: *in_features\n      out_features: 2\n\n  qi:\n    name: folded_normal\n    args:\n      in_features: 64\n      out_features: 2\n\n  loss:\n    name: loss\n    args:\n\n      pi_name: half_normal\n      pi_params:\n        scale: 0.5\n\n      pbg_name: half_normal\n      pbg_params:\n        scale: 1.0\n\n      pprf_name: dirichlet\n      pprf_params: null\n\n      pprf_weight: 0.0001\n      pbg_weight: 0.5\n      pi_weight: 1.0\n      use_robust: true\n      data_dir: *data\n\n      prior_tensor: 'concentration_3d.pt'\n\ndata_loader:\n  name: default\n  args:\n    data_dir: *data\n    batch_size: 256\n    val_split: 0.3\n    test_split: 0.0\n    num_workers: 0\n    include_test: false\n    subset_size: 100\n    cutoff: 2000\n    use_metadata: true\n    shoebox_file_names:\n      counts: \"counts_3d_subset.pt\"\n      masks: \"masks_3d_subset.pt\"\n      stats: \"stats_3d.pt\"\n      reference: \"reference_3d_subset.pt\"\n      standardized_counts: null\n\ntrainer:\n  args:\n    max_epochs: 600\n    accelerator: auto\n    devices: 1\n    logger: true\n    precision: \"32\"\n    check_val_every_n_epoch: 2\n    log_every_n_steps: 1\n    deterministic: false\n    callbacks:\n      pred_writer:\n        output_dir: null\n        write_interval: epoch\n    enable_checkpointing: true\n\nlogger: \n  d: 3\n  h: 21\n  w: 21\n\noutput:\n  refl_file: \"/path/to/.refl\"\n</code></pre>"}]}